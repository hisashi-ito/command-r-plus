#
# cohere_inference yaml
#
inference:
  input_max_tokens: 4096
  max_new_tokens: 512
  min_new_tokens: 1
  temperature: 0.7
  top_k: 40
  top_p: 1.0
  repetition_penalty: 1.15
  diversity_penalty: None
  no_repeat_ngram_size: 0
  num_beams: 1
  num_beam_groups: 1
  seed: 42
  do_sample: True
  use_cache: True
  device: "cuda:0"
  attn_impl: torch
  use_fast: False
  renormalize_logits: False
  num_return_sequences: 1
  bad_words: []
